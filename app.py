# -*- coding: utf-8 -*-
"""Untitled7.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gswOcGYOLAXqBjTCLiCGlH1buaicaX_v
"""

!pip install -q transformers torch torchaudio librosa google-generativeai

import os
import torch
import librosa
import google.generativeai as genai
from transformers import pipeline
from google.colab import files
from IPython.display import display, Markdown
import ipywidgets as widgets

from google.colab import userdata

try:
    # Use Colab's built-in secret manager
    from google.colab import userdata
    GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')
    genai.configure(api_key=GOOGLE_API_KEY)
    print("Google API Key configured successfully!")
except userdata.SecretNotFoundError:
    print('ERROR: Secret "GOOGLE_API_KEY" not found.')
    print('Please go to the "Secrets" tab (key icon on the left) and add your Google API key.')
except Exception as e:
    print(f"An error occurred: {e}")

print("\nLoading local Whisper model... (This may take a few minutes)")
try:
    device = "cuda:0" if torch.cuda.is_available() else "cpu"
    transcriber = pipeline(
        "automatic-speech-recognition",
        model="openai/whisper-small.en", # Changed to a smaller model
        device=device,
        # Removed language='en' as it's an English-only model
    )
    print(f"Whisper model loaded successfully on device: {device}")
except Exception as e:
    print(f"Could not load Whisper model: {e}")
    transcriber = None

def process_audio(audio_path):
    if transcriber is None:
        print("Transcription model is not available.")
        return None, None # Return None for both transcript and summary

    try:
        # --- 1. Local Transcription with Whisper ---
        print("\nStarting transcription...")
        

        # Load audio file using librosa
        audio_input, sample_rate = librosa.load(audio_path, sr=16000, mono=True)
        # progress.value = 0.3

        # Transcribe
        transcription_result = transcriber(audio_input, return_timestamps=True)
        transcript = transcription_result["text"]
        # progress.value = 0.6
        print("Transcription complete.")

        # --- 2. Remote Summarization with Gemini ---
        print("Starting summarization...")
        model = genai.GenerativeModel('gemini-2.5-flash') # Changed to an available model

        prompt = f"""
        Based on the following meeting transcript, provide a structured summary that includes:
        - **Key Decisions**: A bulleted list of important decisions made.
        - **Action Items**: A bulleted list of all assigned tasks, including who is responsible.

        Transcript:
        ---
        {transcript}
        ---
        """
        response = model.generate_content(prompt)
        summary = response.text
        print("Summarization complete.")
        return transcript, summary # Return transcript and summary

    except Exception as e:
        print(f"\nAn error occurred during processing: {e}")
        return None, None # Return None for both transcript and summary
    finally:
        # Clean up the uploaded file
        if os.path.exists(audio_path):
            os.remove(audio_path)

#
# STEP 5: CREATE FILE UPLOAD WIDGET AND RUN (CORRECTED VERSION)
#
print("\n--- Please upload your meeting audio file ---")
uploader = widgets.FileUpload(
    accept='audio/*',  # Accept all audio formats
    multiple=False    # Allow only a single file
)

# This function now correctly receives the file data
def on_upload(change):
    # Check if the 'new' value in the change object is empty
    if not change.new:
        return

    # Get the uploaded file info directly from the change object
    # Iterate through the dictionary of uploaded files
    for file_name, uploaded_file_info in change.new.items():
        # Write the file's content to the Colab environment
        with open(file_name, 'wb') as f:
            f.write(uploaded_file_info['content'])

        print(f"\nFile '{file_name}' uploaded successfully. Starting processing...")

        # Process the audio file
        transcript, summary = process_audio(file_name)

        # Display the results
        if transcript is not None:
            display(Markdown("---"))
            display(Markdown(f"## ðŸ“œ Transcription"))
            display(Markdown(transcript))
        if summary is not None:
            display(Markdown(f"## âœ¨ Summary & Action Items"))
            display(Markdown(summary))
    uploader._counter = 0


# We now observe 'value' which is more reliable
uploader.observe(on_upload, names='value')

display(uploader)

import google.generativeai as genai
from google.colab import userdata

try:
    GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')
    genai.configure(api_key=GOOGLE_API_KEY)
    print("Google API Key configured successfully!")
except userdata.SecretNotFoundError:
    print('ERROR: Secret "GOOGLE_API_KEY" not found.')
    print('Please go to the "Secrets" tab (key icon on the left) and add your Google API key.')
except Exception as e:
    print(f"An error occurred: {e}")

print("\nAvailable Gemini Models:")
for m in genai.list_models():
  if 'generateContent' in m.supported_generation_methods:
    print(f"- {m.name}")

